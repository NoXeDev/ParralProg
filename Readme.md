# Rapport TP/TD Programmation parall√®le / avanc√©e

## Introduction


Le multi-threading est une technique informatique permettant √† un programme d‚Äôex√©cuter plusieurs t√¢ches simultan√©ment en divisant son ex√©cution en threads, ou fils d'ex√©cution. Ces threads partagent les ressources du processus principal et peuvent s‚Äôex√©cuter en parall√®le ou en quasi-simultan√©, selon les capacit√©s du processeur. Cette approche optimise les performances, am√©liore la r√©activit√© des applications, et permet une meilleure utilisation des ressources syst√®me. Cependant, elle introduit une complexit√© accrue, n√©cessitant une gestion rigoureuse pour √©viter les probl√®mes de concurrence ou de synchronisation.

## Sommaire
<a href="#partie-1--introduction-au-calcule-parrall√®le">Partie 1 : Introduction au calcule parrall√®le.</a>
<br>
<a href="#partie-2--m√©thode-de-monte-carlo">Partie 2 : M√©thode de Monte-Carlo</a>

# Partie 1 : Introduction au calcule parrall√®le.

## TP 1 : Simulation du mouvement d'un ou plusieurs mobiles

En Java, un thread est une unit√© d'ex√©cution permettant d'effectuer plusieurs t√¢ches simultan√©ment dans un programme. L'interface `Runnable` offre une mani√®re d'impl√©menter des threads sans h√©riter de la classe `Thread`. En impl√©mentant `Runnable`, on d√©finit la m√©thode `run()` qui contient le code que le thread doit ex√©cuter. Ensuite, un objet `Thread` utilise cette instance de `Runnable` pour lancer l'ex√©cution concurrente avec la m√©thode `start()`. L'utilisation de `Runnable` est souvent privil√©gi√©e, car elle permet de s√©parer la logique m√©tier de l'impl√©mentation du thread, offrant ainsi plus de flexibilit√©.

### Exercice 1

Dans l'exercice 1, il est demand√© de cr√©er une simple fen√™tre avec un petit carr√© (UnMobile) se d√©pla√ßant de gauche √† droite.  
Le code du mobile √©tant d√©j√† impl√©ment√©, la seule chose √† faire est de cr√©er le code de la fen√™tre avec les lignes suivantes :

```java
class UneFenetre extends JFrame // Cr√©ation de la classe
{
    UnMobile sonMobile; // d√©claration du mobile
    private final int LARG=400, HAUT=250; // d√©claration des constantes largeur + hauteur
    
    public UneFenetre()
    {
        sonMobile = new UnMobile(LARG, HAUT); // Ici on instancie la classe un Mobile 
        add(sonMobile); // Cette ligne ajoute la classe sonMobile au JFrame

        Thread threadMobile = new Thread(sonMobile); // Cette ligne cr√©e le thread sonMobile ; pour l'instant il est juste cr√©√© et reste √©teint
        threadMobile.start(); // Cette fonction d√©marre le thread et ex√©cute la fonction run de notre classe sonMobile.

        setSize(LARG, HAUT); // D√©finition des dimensions de la fen√™tre
        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); // D√©finition de l'op√©ration par d√©faut lors de la fermeture de la fen√™tre Java
        setVisible(true); // Affiche la fen√™tre
    }
}
```

Ici, il s'agit simplement de cr√©er un thread et de le lancer avec `.start()`.

Par la suite, il faudra faire en sorte que le mobile reparte en sens inverse lorsqu'il atteint une extr√©mit√© de la fen√™tre. Pour cela, plusieurs choix √©taient possibles ; j'ai personnellement choisi celui-ci :

```java
public void run()
{
    for (sonDebDessin=0; sonDebDessin < saLargeur - sonPas; sonDebDessin+= sonPas)
    {
        repaint();
        try{Thread.sleep(sonTemps);}
        catch (InterruptedException telleExcp)
            {telleExcp.printStackTrace();}
    }
    for (sonDebDessin=saLargeur - sonPas; sonDebDessin >= 0 + sonPas; sonDebDessin-= sonPas)
    {
        repaint();                                      // Duplication de la boucle for avec un compteur partant de la valeur de fin de l'autre
        try{Thread.sleep(sonTemps);}                    // Et arrivant jusqu'√† 0 (+ sonPas pour assurer un petit d√©calage esth√©tique)
        catch (InterruptedException telleExcp)          // sonMobile partira de l'extr√™me droite pour finir √† l'extr√™me gauche
            {telleExcp.printStackTrace();}
    }
}
```

### Exercice 2

Dans l'exercice 2, on ajoute un simple bouton start/stop pour g√©rer l'ex√©cution du threadMobile (avec les m√©thodes `.suspend()` & `.resume()` de la classe Thread).

Pour cela, on ajoute le code suivant √† la classe `UneFenetre` :

```java
class UneFenetre extends JFrame // Cr√©ation de la classe
{
    UnMobile sonMobile; // d√©claration du mobile
    private final int LARG=400, HAUT=250; // d√©claration des constantes largeur + hauteur
    boolean isRunning = true; // Variable de gestion de l'√©tat du thread
    
    public UneFenetre()
    {
        sonMobile = new UnMobile(LARG, HAUT); // Ici on instancie la classe un Mobile 
        add(sonMobile); // Cette ligne ajoute la classe sonMobile au JFrame

        JButton controlButton = new JButton("Start/Stop"); // Ici on cr√©e une classe JButton avec comme titre "Start/Stop"
        add(controlButton, "South");  // Ajout du bouton au JFrame en position "sud" (autrement dit en bas de la fen√™tre)

        Thread threadMobile = new Thread(sonMobile); // Cette ligne cr√©e le thread sonMobile, pour le moment il est juste cr√©√© et reste √©teint
        threadMobile.start(); // Cette fonction d√©marre le thread et ex√©cute la fonction run de notre classe sonMobile.

        /*
            Le bloc d'instructions ci-dessous ajoute un "event handler" pour d√©clencher la fonction donn√©e en param√®tre en fonction d'un √©v√®nement particulier (ici, appuyer sur le bouton Start/Stop).

            *Notez que la variable isRunning permet le bon suivi de l'ex√©cution du thread*
        */
        controlButton.addActionListener(new ActionListener() {
            public void actionPerformed(ActionEvent e) {
                if (isRunning) {
                    threadMobile.suspend(); // Gr√¢ce √† cette fonction, le thread du mobile s'arr√™te et attend la fonction .resume()
                } else {
                    threadMobile.resume(); // Ici, le thread mis en pause avec .suspend() reprend l√† o√π il s'√©tait arr√™t√©
                }
                isRunning = !isRunning;
            }
        });

        setSize(LARG, HAUT);
        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
        setVisible(true);
    }
}
```

### Exercice 3

L'exercice 3 nous demande de modifier le code en utilisant la classe GridLayout pour cr√©er une grille de 2 par 2 avec un bouton et un mobile pour chaque cellule. J'ai d√©cid√© de ne pas reprendre exactement le code de l'exercice pour mieux int√©grer cet exercice dans mon programme. Voici le r√©sultat :

```java
class UneFenetre extends JFrame 
{
    UnMobile sonMobile1, sonMobile2;
    JButton controlButton1, controlButton2;
    Thread threadMobile1, threadMobile2;
    private final int LARG=400, HAUT=250;
    boolean isRunning1 = true, isRunning2 = true;
    
    public UneFenetre()
    {
        // Param√©trage de la grille de 2 par 2
        Container leConteneur = getContentPane();
        leConteneur.setLayout(new GridLayout(2, 2));

        // Cr√©ation du premier mobile / bouton / thread
        sonMobile1 = new UnMobile(LARG, HAUT);
        controlButton1 = new JButton("Start/Stop");

        leConteneur.add(controlButton1, "South");
        leConteneur.add(sonMobile1);

        threadMobile1 = new Thread(sonMobile1);
        threadMobile1.start();

        controlButton1.addActionListener(new ActionListener() {
            public void actionPerformed(ActionEvent e) {
                if (isRunning1) {
                    threadMobile1.suspend();
                } else {
                    threadMobile1.resume();
                }
                isRunning1 = !isRunning1;
            }
        });

        // Cr√©ation du deuxi√®me mobile / bouton / thread
        sonMobile2 = new UnMobile(LARG, HAUT);
        controlButton2 = new JButton("Start/Stop");

        leConteneur.add(controlButton2, "South");
        leConteneur.add(sonMobile2);

        threadMobile2 = new Thread(sonMobile2);
        threadMobile2.start();

        controlButton2.addActionListener(new ActionListener() {
            public void actionPerformed(ActionEvent e) {
                if (isRunning2) {
                    threadMobile2.suspend();
                } else {
                    threadMobile2.resume();
                }
                isRunning2 = !isRunning2;
            }
        });

        // Param√©trage de la fen√™tre
        setSize(LARG*2, HAUT*2);
        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
        setVisible(true);
    }
}
```

Ici, j'ai simplement dupliqu√© le code servant √† cr√©er un bouton et un thread mobile pour en g√©rer un deuxi√®me. Le fonctionnement est exactement le m√™me, sauf que cette fois, la classe Container aura un layout de type GridLayout, formant une grille 2x2. La gestion des threads reste inchang√©e.

Voici le sch√©ma UML final du TP1 :

![uml](res/tp1ulmschema.png)

## TP 2 : Affichage - Exclusion et Semaphore

Dans le TP2, on introduit le concept de `Semaphore`.  
Un `Semaphore` est un moyen de contr√¥ler l'acc√®s √† une ressource partag√©e entre diff√©rents threads pour √©viter les conflits et optimiser l'utilisation d'un programme.

Tout le fonctionnement du s√©maphore repose sur sa valeur enti√®re. Voici comment elle est manipul√©e dans la classe :

- Une fonction `syncWait()` v√©rifie la valeur du s√©maphore ; si elle est √©gale √† 0, la fonction bloque l'ex√©cution du thread avec la m√©thode `wait()`, sinon elle d√©cr√©mente cette valeur de un.
- Une fonction `syncSignal()` r√©-incr√©mente la valeur interne du s√©maphore de un et d√©bloque tous les threads pr√©c√©demment bloqu√©s sur `wait()` gr√¢ce √† la fonction `notifyAll()`.

La probl√©matique du TP2 est la suivante :

Comment s'assurer que la console affiche bien un message au format `AABBB` ?

Comme la gestion de l'affichage est multi-thread, les threads ne g√®rent pas la priorit√© d'affichage, ce qui entra√Æne un affichage d√©sordonn√© dans la console, par exemple `ABABB`. Les threads peuvent s'ex√©cuter en m√™me temps, produisant un mauvais r√©sultat. Pour √©viter cela, on utilise la classe `Semaphore` pour prot√©ger la boucle `for` qui g√®re l'affichage en tant que ressource critique. Voici le fonctionnement :

- 4 threads sont lanc√©s en m√™me temps : "AAA", "BB", "CCCC", "DDD".
- Le premier thread qui atteint la fonction `syncWait()` d√©cr√©mente la valeur du `Semaphore` √† 0 et, ce faisant, verrouille tous les autres threads qui atteindront la fonction `wait()`, car le `Semaphore` est √† 0.
- Lorsque le thread non verrouill√© termine son ex√©cution, il atteint la fonction `syncSignal()`, qui r√©-incr√©mente la valeur du s√©maphore et d√©verrouille tous les autres threads.
- Le premier thread qui atteindra √† nouveau `syncWait()` reproduira le m√™me comportement, et la boucle continuera jusqu'√† la fin du programme.

Gr√¢ce √† ce m√©canisme, les threads s‚Äôemp√™chent mutuellement d‚Äôex√©cuter la m√™me partie de code "critique" en m√™me temps.

Voici le sch√©ma UML final du TP2 :

![uml](res/tp2ulmschema.png)

## TP 3 : Bo√Æte aux lettres et boulangerie  

Le TP 3 introduit le concept de **Blocking Queue** avec, dans un premier temps, l'impl√©mentation simple d'une bo√Æte aux lettres.  
Un producteur d√©pose une lettre, et un consommateur en retire une.  
Cependant, il y a plusieurs conditions :  

- Le producteur ne d√©pose sa "lettre" dans la bo√Æte aux lettres (BAL) que si elle est vide.  
- Le consommateur ne retire une "lettre" de la BAL que si elle en contient une.  

On peut d√©j√† voir, √† travers cet √©nonc√©, que le producteur et le consommateur sont deux threads distincts, et que la bo√Æte aux lettres constitue ici une section critique.  

La bo√Æte aux lettres fera office de file d'attente bloquante pour les threads, afin de respecter les diff√©rentes conditions.  

```java
public synchronized void send(String letter) {
        try {
            while(currentLetter != null) {
                wait();   // Ici, si la bo√Æte aux lettres contient d√©j√† une lettre, le producteur sera oblig√© de s'arr√™ter √† son prochain envoi.
            }

            System.out.println("LetterBox send: " + letter);
            currentLetter = letter;
            notify();     // Ici, on d√©bloque le thread du consommateur s'il est bloqu√© √† l'instruction wait().
        }
        catch(InterruptedException e) {
            e.printStackTrace();
        }
    }

    public synchronized String receive() {
        try {
            while (currentLetter == null) {
                wait(); // Ici, si la bo√Æte aux lettres est vide, le consommateur sera oblig√© de s'arr√™ter √† son prochain essai de retrait.
            }
            String letter = currentLetter; // copie

            currentLetter = null;
            notify();       // Ici, on d√©bloque le thread du producteur s'il est bloqu√© √† l'instruction wait().

            System.out.println("LetterBox receive: " + letter);
            return letter;
        }
        catch(InterruptedException e) {
            e.printStackTrace();
            return "failed";
        }
    }
```  

Ici, la fonction `send()` bloque le thread du producteur si la bo√Æte aux lettres contient d√©j√† une lettre ; il y a une mise en attente dans la file. Le thread sera d√©bloqu√© uniquement si la fonction `receive()` atteint le `notify()`.  
Tandis que la fonction `receive()` bloque le thread du consommateur si la bo√Æte aux lettres est vide ; il ne peut pas r√©cup√©rer de lettre lorsqu'il n'y en a pas.  
Le thread sera d√©bloqu√© uniquement si la fonction `send()` atteint le `notify()`.  

Par la suite, on impl√©mentera la possibilit√© de mettre fin aux threads avec la lettre "Q", et on ajoutera une interface graphique simple, ce qui nous permettra, en plus, d'√©couter le clavier de l'utilisateur pour envoyer des lettres dans la file gr√¢ce √† l'interface `KeyListener`.  

Voici le sch√©ma UML final de la premi√®re partie de ce TP :  

![uml](res/tp3ulmschema.png)  

Cette premi√®re partie du TP3 nous apprend √† impl√©menter un syst√®me de file d'attente (ou **Blocking Queue**), mais la deuxi√®me partie nous apprendra √† impl√©menter un fonctionnement plus avanc√© de ce syst√®me en utilisant, cette fois, des classes propres √† Java.  

Dans la 2·µâ partie du TP, la majorit√© de l'exercice tourne autour de la classe `ArrayBlockingQueue`.  
On retrouve le m√™me fonctionnement que notre bo√Æte aux lettres, mais cette fois-ci, il n'est pas question d'un seul √©l√©ment (une lettre), mais bien d'une vraie file d'attente avec plusieurs √©l√©ments.  

Ici, les `consommateurs` seront remplac√©s par la classe `Mangeur`, les `producteurs` par la classe `Boulanger`, la bo√Æte aux lettres par la classe `Boulangerie`, et les lettres par une simple classe `Pain`.  

Voici un extrait de la classe `Boulangerie`, qui est le c≈ìur de la coordination des threads :  

```java
private BlockingQueue<Pain> queue =  new ArrayBlockingQueue<Pain>(20); // Voici la classe principalement vis√©e par ce paradigme.

public boolean depose(Pain pain) throws InterruptedException {
    return queue.offer(pain, 200, TimeUnit.MILLISECONDS);
}

public Pain achete() throws InterruptedException {
    return queue.poll(200, TimeUnit.MILLISECONDS);
}

public int getStock() {
    return queue.size();
}
```  

Cette classe est une version modifi√©e de la classe bien connue `ArrayList`, qui permet de rajouter, supprimer ou modifier des √©l√©ments dans un tableau.  

Les particularit√©s de cette classe sont les suivantes :  

- Cette classe utilise une structure de donn√©es en file, dite FIFO (First In, First Out).  
- Les fonctions d'ajout et de r√©cup√©ration (`offer()` & `poll()`) sont dites "bloquantes". Cela signifie que lorsque le nombre d'√©l√©ments dans la file d√©passe le nombre maximal param√©tr√© lors de l'instanciation de la classe, la fonction bloque le thread qui l'ex√©cute jusqu'√† ce qu'un autre thread lib√®re de la place. Et inversement, lorsque la file est vide et qu'on essaye de r√©cup√©rer un √©l√©ment, la fonction bloque le thread jusqu'√† ce que la file soit de nouveau remplie.  

C'est le principe de la classe `ArrayBlockingQueue`.  

Voici le sch√©ma final de la seconde partie de ce TP3 :  

![uml](res/tp3blockingqueuesulmschema.png)  

## Conclusion

Au travers de ces trois TP, nous avons explor√© diff√©rents concepts fondamentaux de la programmation parall√®le, notamment le multi-threading, la synchronisation, et la gestion des ressources partag√©es.

Dans le premier TP, nous avons introduit la notion de threads et appris √† les g√©rer pour cr√©er des applications interactives et r√©actives.
Le deuxi√®me TP nous a familiaris√©s avec les m√©canismes de synchronisation, comme les s√©maphores, pour garantir l'exclusion mutuelle et √©viter les conflits entre threads.
Enfin, le troisi√®me TP nous a permis de mettre en ≈ìuvre des syst√®mes de communication entre threads via des files bloquantes, tout en d√©couvrant des abstractions avanc√©es de Java comme ArrayBlockingQueue.


----
# **Partie 2 : M√©thode de Monte-Carlo**

<i>Cette partie 2 a √©t√© r√©dig√©e en partie gr√¢ce √† l'aide de l'intelligence artificielle ChatGPT</i>

## **Introduction**

La m√©thode de Monte Carlo (MC) permet d‚Äôestimer œÄ en utilisant des tirages al√©atoires. Cette approche est facilement parall√©lisable et peut √™tre impl√©ment√©e sur des architectures √† m√©moire partag√©e ou distribu√©e.

### **Principe de la m√©thode Monte Carlo**

On consid√®re un quart de disque de rayon $r = 1$ inscrit dans un carr√© de c√¥t√© 1.
- Aire du quart de disque : $A_{	ext{quartD}} = \frac{\pi}{4}$
- Aire du carr√© : $A_c = 1$
- Probabilit√© qu‚Äôun point al√©atoire $(x_p, y_p)$ appartienne au quart de disque :  
  $$P = \frac{A_{	ext{quartD}}}{A_c} = \frac{\pi}{4}$$

L‚Äôapproximation de œÄ se fait via la fr√©quence des points appartenant au quart de disque :  
  $$\pi \approx 4 \times \frac{n_{	ext{cible}}}{n_{	ext{tot}}}$$

## **I. Algorithme s√©quentiel**

```c
n_cible = 0;
for (p = 0; n_tot > 0; n_tot--) {
    x_p = rand();  // G√©n√©rer un nombre al√©atoire entre ]0,1[
    y_p = rand();
    if ((x_p * x_p + y_p * y_p) < 1) {
        n_cible++;
    }
}
pi = 4 * n_cible / n_tot;
```

### D√©composition des √©tapes : 
- √©tape 1 : Tirer des points al√©atoires x/y entre 0 et 1
- √©tape 2 : Compter les points qui sont dans le quart de disque
- √©tape 3 : Calculer la valeur de pi a partir de se compteur

## **II. Parall√©lisation**

### **A. It√©ration parall√®le**

L'algorithme est parall√©lis√© en divisant les tirages entre plusieurs threads.

#### **T√¢ches identifi√©es**

1. **G√©n√©ration des points** $(x_p, y_p)$ (ind√©pendants, parall√©lisables).
2. **V√©rification de la condition $x_p^2 + y_p^2 < 1$** et incr√©mentation de `n_cible` (n√©cessite une synchronisation).
3. **Calcul final de œÄ** apr√®s la collecte des r√©sultats.

#### **Probl√®mes et solutions**
- **Conflits d'acc√®s sur `n_cible`** ‚Üí Utilisation d'une variable atomique ou d'un verrou. (mutex / semaphore)

#### **Algorithme parall√®le avec boucle `parallel for`**

```c
function TirerPoint() {
    x_p = rand();
    y_p = rand();
    return ((x_p * x_p + y_p * y_p) < 1);
}

n_cible = 0;
parallel for (p = 0; n_tot > 0; n_tot--) {
    if (TirerPoint()) {
        n_cible++;
    }
}
pi = 4 * n_cible / n_tot;
```

### **B. Mod√®le Master/Worker**

- **Master** : r√©partit le travail.
- **Workers** : r√©alisent une partie des tirages et renvoient leur r√©sultat.
- **Synchronisation minimale** car chaque Worker utilise un compteur local.

#### **Algorithme Master/Worker**

```c
function MCWorker(n_charge) {
    n_cible_partiel = 0;
    for (p = 0; n_charge > 0; n_charge--) {
        if (TirerPoint()) {
            n_cible_partiel++;
        }
    }
    return n_cible_partiel;
}

n_charge = n_tot / n_workers;
ncibles = [NULL * n_workers];
parallel for (worker = 0; worker < n_workers; worker++) {
    ncibles[worker] = MCWorker(n_charge);
}
n_cible = sum(ncibles);
pi = 4 * n_cible / n_tot;
```

### **Avantages du mod√®le Master/Worker**

- **R√©duction des conflits** : chaque Worker travaille sur des donn√©es locales.
- **Meilleure scalabilit√©** : charge r√©partie entre plusieurs threads/machines.
- **Adaptabilit√© aux environnements distribu√©s** : chaque Worker peut s‚Äôex√©cuter sur une machine distincte.

## **III. Mise en ≈ìuvre sur Machine**

### **A. D√©finitions et contexte**

### **1. `Callable<T>` : Une t√¢che qui retourne un r√©sultat**
#### **D√©finition :**
Un **`Callable<T>`** est une interface qui repr√©sente une **t√¢che parall√®le capable de renvoyer une valeur**. Contrairement √† **`Runnable`**, qui ne retourne rien (`void`), un **`Callable<T>`** retourne un objet de type `T` et peut lever des exceptions (`Exception`).  

#### **Syntaxe :**
```java
import java.util.concurrent.Callable;

class MaTache implements Callable<Integer> {
    @Override
    public Integer call() throws Exception {
        int resultat = 42;  // Simulation d‚Äôun calcul
        return resultat; 
    }
}
```

#### **Comparaison avec `Runnable`**
| Caract√©ristique | `Callable<T>` | `Runnable` |
|----------------|--------------|------------|
| **Retourne un r√©sultat** | ‚úÖ Oui (`T`) | ‚ùå Non (`void`) |
| **Peut lever une exception** | ‚úÖ Oui (`Exception`) | ‚ùå Non (uniquement `RuntimeException`) |
| **Utilis√© avec** | `ExecutorService.submit()` | `ExecutorService.execute()` |

---

### **2. `Future<T>` : Un conteneur pour un r√©sultat asynchrone**
#### **D√©finition :**
Un **`Future<T>`** repr√©sente un **r√©sultat futur** d‚Äôun **`Callable<T>`**. Il permet :
- De **v√©rifier si la t√¢che est termin√©e** (`isDone()`).
- De **r√©cup√©rer le r√©sultat** (`get()`), en **bloquant si n√©cessaire**.
- D‚Äô**annuler** la t√¢che (`cancel()`).

#### **Exemple d'utilisation d'un `Future`**
```java
import java.util.concurrent.*;

public class ExempleFuture {
    public static void main(String[] args) throws Exception {
        ExecutorService executor = Executors.newFixedThreadPool(2);

        // Soumission d'une t√¢che avec Callable
        Future<Integer> futureResult = executor.submit(() -> {
            Thread.sleep(2000); // Simule un calcul long
            return 42;
        });

        // V√©rifie si la t√¢che est termin√©e
        while (!futureResult.isDone()) {
            System.out.println("T√¢che en cours...");
            Thread.sleep(500);
        }

        // R√©cup√®re le r√©sultat (bloque si pas termin√©)
        int resultat = futureResult.get();
        System.out.println("R√©sultat obtenu : " + resultat);

        executor.shutdown();
    }
}
```

### **R√©sum√©**
| **Concept** | **D√©finition** | **Utilit√©** |
|------------|---------------|-------------|
| `Callable<T>` | Interface repr√©sentant une **t√¢che parall√®le** qui retourne un **r√©sultat** | Permet d‚Äôeffectuer un calcul et r√©cup√©rer un r√©sultat |
| `Future<T>` | Objet contenant le **r√©sultat futur** d‚Äôun `Callable<T>` | Permet de r√©cup√©rer un r√©sultat **une fois la t√¢che termin√©e** |

---

### **3. Variables Atomiques (`AtomicInteger`, `AtomicLong`) : Gestion S√©curis√©e des Donn√©es Partag√©es**  

### **Probl√®me des Variables Partag√©es en Multi-Threading**
Lorsque plusieurs threads acc√®dent et modifient **simultan√©ment** une m√™me variable, des **probl√®mes de concurrence** peuvent survenir, comme des r√©sultats incoh√©rents.  

#### **Exemple sans variable atomique (probl√®me de synchronisation)**  
```java
class Compteur {
    private int valeur = 0;

    public void incrementer() {
        valeur++;  // Probl√®me : l'incr√©mentation n'est PAS atomique !
    }

    public int getValeur() {
        return valeur;
    }
}

public class TestCompteur {
    public static void main(String[] args) throws InterruptedException {
        Compteur compteur = new Compteur();

        // Deux threads qui incr√©mentent en m√™me temps
        Thread t1 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) compteur.incrementer();
        });

        Thread t2 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) compteur.incrementer();
        });

        t1.start();
        t2.start();
        t1.join();
        t2.join();

        System.out.println("Valeur attendue : 2000");
        System.out.println("Valeur r√©elle : " + compteur.getValeur()); // Erreur possible !
    }
}
```
**R√©sultat possible (erreur due √† la concurrence) :**  
```
Valeur attendue : 2000  
Valeur r√©elle : 1985  (ou autre valeur incorrecte)
```
Le probl√®me vient du fait que l‚Äôop√©ration `valeur++` n'est **pas atomique**, c‚Äôest-√†-dire qu‚Äôelle se d√©compose en plusieurs instructions machine :
1. Lire la valeur actuelle de `valeur`
2. Ajouter 1
3. √âcrire la nouvelle valeur  

Si deux threads ex√©cutent cette op√©ration **en m√™me temps**, l‚Äôun peut √©craser le r√©sultat de l‚Äôautre.

---

### **Solution : `AtomicInteger` pour une Incr√©mentation S√©curis√©e**
La classe **`AtomicInteger`** fournit des **op√©rations atomiques** comme `incrementAndGet()`, qui garantissent que l'incr√©mentation est **indivisible et sans interf√©rence**.

#### **Exemple avec `AtomicInteger` (r√©solution du probl√®me)**
```java
import java.util.concurrent.atomic.AtomicInteger;

class CompteurAtomique {
    private AtomicInteger valeur = new AtomicInteger(0);

    public void incrementer() {
        valeur.incrementAndGet(); // Incr√©mentation atomique
    }

    public int getValeur() {
        return valeur.get();
    }
}

public class TestCompteurAtomique {
    public static void main(String[] args) throws InterruptedException {
        CompteurAtomique compteur = new CompteurAtomique();

        Thread t1 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) compteur.incrementer();
        });

        Thread t2 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) compteur.incrementer();
        });

        t1.start();
        t2.start();
        t1.join();
        t2.join();

        System.out.println("Valeur attendue : 2000");
        System.out.println("Valeur r√©elle : " + compteur.getValeur()); // Toujours correcte
    }
}
```
**R√©sultat toujours correct :**
```
Valeur attendue : 2000  
Valeur r√©elle : 2000
```

---

### **3. Comparaison entre Synchronisation et Variables Atomiques**
| Approche | Description | Avantages | Inconv√©nients |
|----------|------------|-----------|--------------|
| **`synchronized` (verrou)** | Prot√®ge un bloc de code contre les acc√®s concurrents | Fiable et applicable √† toute structure | Peut ralentir l‚Äôex√©cution √† cause des verrous |
| **`AtomicInteger`** | Op√©rations atomiques sur un entier | Tr√®s performant car sans verrou | Limit√© aux types de donn√©es atomiques (`int`, `long`, `boolean`) |




## **B. Analyse de `Assignment102.java`**

### **1. Structure et API utilis√©e**
#### **a) Parall√©lisation avec `ExecutorService` et `Runnable`**
Le programme `Assignment102` utilise **`ExecutorService`** pour ex√©cuter des t√¢ches parall√®les. Il repose sur un **pool de threads adaptatif** (`newWorkStealingPool`) et ex√©cute chaque tirage Monte Carlo via une t√¢che **`Runnable`**.  

#### **Extrait du code : Cr√©ation des threads avec `Runnable`**
```java
class MonteCarlo implements Runnable {
    @Override
    public void run() {
        double x = Math.random();
        double y = Math.random();
        if (x * x + y * y <= 1)
            nAtomSuccess.incrementAndGet(); // Incr√©mentation atomique si le point est dans le cercle
    }
}
```
- **Chaque thread g√©n√®re un point `(x, y)` al√©atoire**.
- **Si le point est dans le quart de disque**, `nAtomSuccess.incrementAndGet()` est appel√© pour compter le succ√®s.

---

#### **b) Gestion des t√¢ches avec `ExecutorService`**
```java
ExecutorService executor = Executors.newWorkStealingPool(nProcessors);
for (int i = 1; i <= nThrows; i++) {
    Runnable worker = new MonteCarlo();
    executor.execute(worker);
}
executor.shutdown();
while (!executor.isTerminated()) {} // Attente de la fin des t√¢ches
```
- **Un pool de threads est cr√©√©** avec `newWorkStealingPool(nProcessors)`, qui exploite le **nombre optimal de threads**.
- **Chaque tirage Monte Carlo est soumis comme une t√¢che `Runnable`**.
- **Le programme attend la fin de l‚Äôex√©cution** avec `executor.shutdown()` et `while (!executor.isTerminated()) {}`.

---

#### **c) Calcul et stockage du r√©sultat**
```java
value = 4.0 * nAtomSuccess.get() / nThrows; // Approximation de Pi
System.out.println("Approx value:" + value);
System.out.println("Difference to exact value of pi: " + (value - Math.PI));
```
- `nAtomSuccess.get()` retourne **le nombre total de points dans le quart de disque**.
- **L'approximation de œÄ est obtenue par la formule** :  
  \[
  \pi \approx 4 \times \frac{\text{nombre de succ√®s}}{\text{nombre total de lancers}}
  \]
  
---

### **2. Probl√®mes et limites**
#### **üö© Probl√®me de synchronisation avec `AtomicInteger`**
L‚Äôutilisation de `AtomicInteger` pour **chaque tirage individuel** introduit un **goulot d‚Äô√©tranglement**. En effet, `incrementAndGet()` force **une synchronisation entre threads**, ce qui r√©duit les performances.

**‚úÖ Solution possible :**  
- **Utiliser un compteur local dans chaque thread**, puis agr√©ger √† la fin, **r√©duisant ainsi la contention sur `AtomicInteger`**.

---

### **3. Comparaison avec le pseudo-code**
| **Pseudo-code Monte Carlo** | **`Assignment102.java`** |
|--------------------------|-------------------|
| Boucle `for` sur `N` it√©rations | Boucle `for` soumettant `N` t√¢ches `Runnable` |
| V√©rification `(x¬≤ + y¬≤ ‚â§ 1)` | `if (x * x + y * y <= 1) nAtomSuccess.incrementAndGet();` |
| Calcul final de œÄ | `4.0 * nAtomSuccess.get() / nThrows;` |

---

## **C. Analyse de `Pi.java`**

### **1. Structure et API utilis√©e**
Contrairement √† `Assignment102`, le programme `Pi.java` utilise **une approche Master/Worker avec `Callable<T>` et `Future<T>`**, qui am√©liore la gestion du parall√©lisme.

---

**a) Cr√©ation des t√¢ches avec `Callable<Long>`** <br>
Au lieu de **soumettre une t√¢che par tirage individuel**, `Pi.java` regroupe **plusieurs tirages dans une seule t√¢che** (meilleur √©quilibre entre parall√©lisme et performance).

#### **Extrait : Classe `Worker` qui ex√©cute les calculs**
```java
class Worker implements Callable<Long> {   
    private int numIterations;
    public Worker(int num) { this.numIterations = num; }

    @Override
    public Long call() {
        long circleCount = 0;
        Random prng = new Random();
        for (int j = 0; j < numIterations; j++) {
            double x = prng.nextDouble();
            double y = prng.nextDouble();
            if ((x * x + y * y) < 1)  ++circleCount;
        }
        return circleCount; // Retourne le nombre de succ√®s
    }
}
```
- **Chaque `Worker` g√®re `numIterations`** (au lieu d‚Äôun seul tirage comme dans `Assignment102`).
- **Utilisation de `Callable<Long>` au lieu de `Runnable`** :  
  - `Runnable` ne retourne **pas de valeur**  
  - `Callable<Long>` retourne **le nombre de succ√®s (points dans le cercle)**.

---

**b) Gestion des threads avec `Future<Long>`** <br>
La classe `Master` g√®re les **threads et l‚Äôagr√©gation des r√©sultats**.

#### **Extrait : Lancement et r√©cup√©ration des r√©sultats**
```java
ExecutorService exec = Executors.newFixedThreadPool(numWorkers);
List<Future<Long>> results = exec.invokeAll(tasks); // Ex√©cution parall√®le

long total = 0;
for (Future<Long> f : results) {
    total += f.get(); // R√©cup√®re chaque r√©sultat
}

double pi = 4.0 * total / totalCount / numWorkers;
```
- **Cr√©ation d'un pool fixe de `numWorkers` threads** (`FixedThreadPool`).
- **Les t√¢ches sont soumises en parall√®le et `invokeAll()` attend qu'elles terminent**.
- **Agr√©gation finale : r√©cup√©ration des r√©sultats avec `Future<Long>.get()`**.

---

**c) Calcul final et affichage des r√©sultats** <br>
```java
System.out.println("\nPi : " + pi );
System.out.println("Error: " + (Math.abs((pi - Math.PI)) / Math.PI) +"\n");
```
L'erreur est calcul√©e et affich√©e, comme dans `Assignment102`.

---

### **2. Probl√®mes et limites**
#### **‚úÖ Meilleure gestion des threads**
- `Pi.java` **√©vite le probl√®me de contention de `AtomicInteger`** en utilisant des **compteurs locaux** dans chaque `Worker`, puis **une agr√©gation finale avec `Future<Long>`**.
- Moins de **synchronisation co√ªteuse**, car `Future.get()` bloque **uniquement lors de l'agr√©gation**, et non √† chaque tirage.

---

## **D. Comparaison entre `Assignment102.java` et `Pi.java`**
| Crit√®re | `Assignment102.java` | `Pi.java` |
|---------|-----------------|----------|
| **Mod√®le** | Parall√©lisation simple avec `Runnable` | Mod√®le Master/Worker avec `Callable<T>` |
| **Type de pool** | `newWorkStealingPool(nProcessors)` | `FixedThreadPool(numWorkers)` |
| **Gestion des r√©sultats** | `AtomicInteger.incrementAndGet()` pour chaque tirage | Agr√©gation finale via `Future<Long>.get()` |
| **Probl√®me majeur** | Contention sur `AtomicInteger` | Synchronisation uniquement √† la fin |
| **Performance** | Plus de synchronisation, moins efficace | Plus efficace avec `Callable<T>` |

---

### **Conclusion**
- **`Assignment102.java` est plus simple mais inefficace**, √† cause du goulot d‚Äô√©tranglement sur `AtomicInteger`.
- **`Pi.java` optimise la parall√©lisation avec des `Callable<T>` et `Future<T>`**, r√©duisant les synchronisations inutiles.
- **Meilleure approche : `Pi.java`**, surtout sur des machines multic≈ìurs.


## **E. Sch√©ma UML de pi.java et assignment102.java**
![uml](res/Diagramme_UML_TP4.jpg)  

## **F. Approche Master/Worker**

### **1. Introduction**

L'approche Master/Worker repose sur la d√©l√©gation des t√¢ches √† plusieurs travailleurs (Workers) par un ma√Ætre (Master). Le Master se charge de distribuer le travail, de collecter les r√©sultats et de les agr√©ger pour obtenir le r√©sultat final. Cette d√©coupe se fait a travers plusieurs codes/executions diff√©rentes, ce qui fait que la mise en place d'une communication r√©seaux est facilement impl√©mentable.

### **2. Architecture**

* **Master :**
    * Lance une connexion vers chaques Workers via des `sockets`
    * Envoi par messages, les param√®tres d'√©xecutions : (points a g√©n√©rer `totalCount`, processus a utiliser `numProcess`)
    * Re√ßois pour chaques `sockets` le nombre de points tombant dans le quart de disque de chaque Worker
    * Calcule Pi √† partir des r√©sultats obtenu par chaques Workers

* **Workers :**
    * Cr√©er un `socket` qui attend une connexion master et √©coute ses messages 
    * Re√ßois des param√®tres d'√©xecutions : ici le nombre de points √† tirer
    * Fait ses tirages al√©atoires en fonction du nombres de points √† tirer
    * Envoi le r√©sultat `circleCount` au Master via le `socket`

![mws](res/master_worker_schema.png)  

### **3. Les sockets**

Java fournit deux principaux types de sockets :

1. **Sockets TCP (Transmission Control Protocol)**
   - Bas√©s sur une connexion fiable.
   - Garantissent l'ordre des messages et l'int√©grit√© des donn√©es.
   - Exemples : HTTP, FTP, SMTP.

2. **Sockets UDP (User Datagram Protocol)**
   - Connexion non fiable, sans garantie d‚Äôordre ni d'int√©grit√©.
   - Plus rapide et l√©ger que TCP.
   - Exemples : VoIP, Streaming vid√©o.

---

**Dans cet excercice nous allons nous concentrer d'avantage sur les sockets TCP car nous voulons une connexion fiable mais pas forc√©ment rapide**


#### **üîπ Serveur TCP (Java)**
Le serveur utilise `ServerSocket` pour √©couter les connexions entrantes.

```java
import java.io.*;
import java.net.*;

public class Serveur {
    public static void main(String[] args) {
        try (ServerSocket serverSocket = new ServerSocket(1234)) {
            System.out.println("Serveur en attente de connexion...");

            Socket socket = serverSocket.accept();
            System.out.println("Client connect√©");

            BufferedReader input = new BufferedReader(new InputStreamReader(socket.getInputStream()));
            PrintWriter output = new PrintWriter(socket.getOutputStream(), true);

            String message = input.readLine();
            System.out.println("Message re√ßu : " + message);
            output.println("Message bien re√ßu");

            socket.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

#### **üîπ Client TCP (Java)**
Le client utilise `Socket` pour se connecter au serveur.

```java
import java.io.*;
import java.net.*;

public class Client {
    public static void main(String[] args) {
        try (Socket socket = new Socket("localhost", 1234)) {
            BufferedReader input = new BufferedReader(new InputStreamReader(socket.getInputStream()));
            PrintWriter output = new PrintWriter(socket.getOutputStream(), true);

            output.println("Hello, Serveur !");
            String response = input.readLine();
            System.out.println("R√©ponse du serveur : " + response);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

---

### **4. Analyse code Master**

Le code `MasterSocket.java` utilise donc le syst√®me de socket pour organiser la parrall√©lisation du calcule. 

1. Initialisation des varaibles
```java
long totalCount = 1000000000; // total number of throws on a Worker
int total = 0; // total number of throws inside quarter of disk
double pi; 
```

2. Lecture des entr√©es au clavier, pour sp√©cifier le nombre de worker et leurs ports / ip respectives
```java
int numWorkers = maxServer;
BufferedReader bufferRead = new BufferedReader(new InputStreamReader(System.in)); // Cr√©ation d'un object de lecture d'entr√©es
String s; 

// Purement esth√©tique
System.out.println("#########################################");
System.out.println("# Computation of PI by MC method        #");
System.out.println("#########################################");

// Lecture du nombre de worker
System.out.println("\n How many workers for computing PI (< maxServer): ");
try{
    s = bufferRead.readLine();
    numWorkers = Integer.parseInt(s);
    System.out.println(numWorkers);
}
catch(IOException ioE){
    ioE.printStackTrace();
}

// Pour chaque worker, demander le port d'acc√®s.
for (int i=0; i<numWorkers; i++){
    System.out.println("Enter worker"+ i +" port : ");
    try{
    s = bufferRead.readLine();
    System.out.println("You select " + s);
    }
    catch(IOException ioE){
    ioE.printStackTrace();
    }
}
```

3. Cr√©ation des `sockets` et pr√©paration des objets de lecture/√©criture des `sockets`
```java
// Pour chaques workers 
for(int i = 0 ; i < numWorkers ; i++) {
    sockets[i] = new Socket(ip, tab_port[i]); // Cr√©ation du socket
    System.out.println("SOCKET = " + sockets[i]);
    
    reader[i] = new BufferedReader( new InputStreamReader(sockets[i].getInputStream())); // Bind d'un object de lecture sur le socket
    writer[i] = new PrintWriter(new BufferedWriter(new OutputStreamWriter(sockets[i].getOutputStream())),true); // Bind d'un object d'√©criture sur le socket
}
```

4. Envoi des param√®tres aux worker via `sockets`
```java
String message_to_send;
message_to_send = String.valueOf(totalCount) + ":" + String.valueOf(numProcess); // Param√®tres sous la forme "nombreiteration:nombreprocessus"

String message_repeat = "y"; 
long stopTime, startTime;

while (message_repeat.equals("y")){

startTime = System.currentTimeMillis();
// initialize workers
for(int i = 0 ; i < numWorkers ; i++) {
    writer[i].println(message_to_send);          // send a message to each worker
}
```

5. Attente des r√©sultats des `Worker`
```java
// Pour chaque worker, on attend le r√©sultat
for(int i = 0 ; i < numWorkers ; i++) {
    tab_total_workers[i] = reader[i].readLine();  
    System.out.println("Client received: " + tab_total_workers[i]);
    System.out.println("Client sent: " + tab_total_workers[i]);
}
```

6. Calculer le r√©sultat a partir des donn√©es `worker`
```java
for(int i = 0 ; i < numWorkers ; i++) {
    total += Long.parseLong(tab_total_workers[i]);
}
pi = 4.0 * total / totalCount / numWorkers;
```

### **5. Analyse code Worker**

Le code `WorkerSocket.java` est un peu plus simple. C'est lui qui re√ßois les ordres du master, et fait les tirages al√©atoires.

1. Attente de la connection socket du Master
```java
ServerSocket s = new ServerSocket(port); // cr√©ation de l'objet socket
System.out.println("Server started on port " + port);
Socket soc = s.accept(); // Cette m√©thode ce bloque jusqu'√† ce qu'une connection arrive.
```

2. Cr√©ation des objets de lecture et √©criture dans le socket
```java
BufferedReader bRead = new BufferedReader(new InputStreamReader(soc.getInputStream()));
PrintWriter pWrite = new PrintWriter(new BufferedWriter(new OutputStreamWriter(soc.getOutputStream())), true);
```

3. Attente / lecture des param√®tres `totalCount` et `numProcess`
```java
String str;
while (isRunning) {
    str = bRead.readLine();          // Lecture du message du Master avec l'objet de lecture du socket
    String workerargs[] = str.split(":");
    
```

4. Tirage al√©atoire et envoi des r√©sultats au Master
```java
    if (!(str.equals("END"))){ // Si le message contient un signal d'arr√™t (la chaine de charact√®re END), le programme s'arr√™te

        // Cr√©ation de l'objet Master du code pi.java pour tirage al√©atoire
        Master m = new Master();

        // Lancement d'une boucle de tirage al√©atoire
        long circleCount = m.doRun(Integer.parseInt(workerargs[0])/Integer.parseInt(workerargs[1]), Integer.parseInt(workerargs[1]), "test.txt");

        // Envoi des r√©sultat au master avec l'objet d'√©criture du socket 
        pWrite.println(circleCount);         
    } else {
        isRunning=false; // Sortie de la boucle principal et arr√™t du code
    }
}
```


## IV. Qualit√© et test de performance
### Objectifs
Les tests de performances, servent √† plusieurs choses :
- La mesure du temps d'execution en fonction du nombre de processeurs.
- L'√©valuation d'une variable qui se nomme le speedup, pendant les mesures de types scalabilit√©es forte et faibles.
- Analyser les r√©sultats et les comparer avec les attentes.
- Identifier les points faibles de l'algorithme parrall√©lis√©.

### Scalabilit√©e forte et faible
La scalabilit√© √©value comment les performances d‚Äôun syst√®me √©voluent lorsqu‚Äôon augmente les ressources (processeurs, m√©moire) ou la charge de travail. On distingue deux types de scalabilit√© :

* Scalabilit√© forte : Elle mesure l‚Äôefficacit√© du parall√©lisme en maintenant la taille du probl√®me fixe tout en augmentant le nombre de ressources. L‚Äôobjectif est de r√©duire le temps d‚Äôex√©cution. Une scalabilit√© forte id√©ale signifie que si l‚Äôon double les ressources, le temps d‚Äôex√©cution est divis√© par deux.
* Scalabilit√© faible : Elle mesure la capacit√© du syst√®me √† maintenir des performances constantes lorsque la charge de travail augmente proportionnellement aux ressources ajout√©es. L‚Äôobjectif est que le temps d‚Äôex√©cution reste stable.

#### **Variable speedup**
Le **Speedup** (acc√©l√©ration) est une mesure cl√© de la scalabilit√© forte. Il est d√©fini comme :  

\[
S_p = \frac{T_1}{T_p}
\]

o√π :  
- \( S_p \) est le speedup avec \( p \) processeurs,  
- \( T_1 \) est le temps d‚Äôex√©cution en mode s√©quentiel (avec 1 processeur),  
- \( T_p \) est le temps d‚Äôex√©cution avec \( p \) processeurs.  

Un **speedup lin√©aire** signifie que l‚Äôacc√©l√©ration est proportionnelle au nombre de processeurs (\( S_p = p \)), ce qui est l‚Äôid√©al mais rarement atteint √† cause des limitations comme la synchronisation et les communications entre processeurs.

![uml](res/SpeedupScalabiliteForte.png)  